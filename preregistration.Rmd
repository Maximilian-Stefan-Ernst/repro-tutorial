---
title: "Preregistration"
author: "Aaron Peikert"
date: "4/12/2021"
output: html_document
params:
  nsim: 2
  nmin: 100
  nmax: 300
  nstep: 100
  seed: 1234
repro:
  packages:
    - tidyverse
    - here
    - lavaan
    - furrr
    - future.batchtools
    - slider
    - patchwork
    - svglite
  scripts:
    - R/simulation.R
---

```{r setup, include=FALSE}
library(tidyverse)
library(lavaan)
library(furrr)
library(slider)
library(patchwork)
source(here::here("R", "simulation.R"))
# if you have access to a hpc envir specify this in R/hpc.R
# if not we use local multicore
# to speed up consider reduce nsim; increase nstep in ↑YAML↑

hpc_config <- here::here("R", "hpc.R")
if(fs::file_exists(hpc_config)){
  source(hpc_config)
} else {
  plan(list(transparent,
       tweak(multisession, workers = 4L)))
}
# debug:
#   plan(transparent)
```

```{r}
loadings_jones_paulhus <- c(38, 31, 40, 52, 59, 71, 62, 46, 51)/100
cohend_jones_paulhus <- c(24, 29, 35)/100
```

```{r models}
true_diff <- 0.2
model_truth <- combine(
  measurement(
    "MACH",
    items("x", 9),
    loadings = round(loadings_jones_paulhus * 0.7, 2)
  ),
  intercepts("MACH", list(0, true_diff)),
  variances("MACH", list(1, 1))
)

model_same <- 
  "MACH =~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9
  MACH ~ c(0,0)*1
  MACH ~~ c(1, NA)*MACH"

model_differ <- 
  "MACH =~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9
  MACH ~ c(0, NA)*1 + c(zero, diff)*1
  MACH ~~ c(1, NA)*MACH"
```

```{r sim}
extract_fns <- list(bic = get_bic, 
                    aic = get_aic,
                    lrt_p = get_lrt_p,
                    delta_p = get_delta_p,
                    estimate = get_estimate,
                    std_delta_p = get_std_delta_p,
                    std_estimate = get_std_estimate)

n_obs <- seq(params$nmin, params$nmax, params$nstep)
n_sim <- params$nsim

setup <- expand_grid(n_obs = n_obs,
                     truth = model_truth,
                     same = model_same,
                     differ = model_differ,
                     mod_load = c(3),
                     mod_int = c(3),
                     extract_fns = list(extract_fns),
                     group.equal = list(c("loadings", "intercepts")),
                     auto.fix.first = FALSE)
to_export <- ls_funs() %>% map(get)
to_export <- c(list(setup = setup), to_export)
RNGkind("L'Ecuyer-CMRG")
set.seed(params$seed)
seed <- params$seed
res_raw %<-% generate_data_setup(n_sim,
                setup,
                furrr_options(
                  globals = to_export,
                  seed = seed,
                  packages = c("furrr", "lavaan", "tidyverse")
                ))
```

```{r write-out, error=TRUE, include=FALSE}
invisible(res_raw)
write_rds(res_raw, here::here("res_raw.rds"))
```

```{r checksum}
# compute checksum using md5
checksum <- digest::digest(res_raw, "md5")
if(checksum != "4203854848ad0cc5d2f848c44b70815d"){
  warning("Mismatch between original and current simulations!
Checksum now is:\n    '", checksum, "'")
}
```

```{r}
res <- res_raw  %>%
  map(bind_rows) %>% 
  bind_rows() %>% 
  mutate(results = map(results, "result")) %>% 
  unnest(results)

res <- mutate(
  res,
  dec_bic = bic < 0,
  dec_aic = aic < 0,
  dec_aic2 = aic < -2,
  dec_lrt_p = lrt_p < 0.05,
  dec_delta_p = delta_p < 0.05)

res_interval <- res %>%
  select(n_obs, std_estimate, mod_load, mod_int) %>% 
  filter(!is.na(std_estimate)) %>% 
  group_by(n_obs, mod_load, mod_int) %>% 
  summarise(interval = list(interval(std_estimate, seq(0.05, .2, 0.01))), 
            .groups = "drop", median = median(std_estimate)) %>% 
  unnest(c(interval)) %>% 
  mutate(width = upper - lower, perc = 1 - alpha) %>% 
  group_by(alpha) %>% 
  arrange(n_obs) %>% 
  mutate(across(c(width, upper, lower),
                ~slide_dbl(.x, mean, na.rm = TRUE, .before = 2, .after = 0, .complete = FALSE))) %>% 
  ungroup() %>% 
  arrange(perc)
```

```{r}
choosen_perc <- .8
choosen_width <- .2
minn <- filter(res_interval, perc == choosen_perc, width < choosen_width) %>% 
  filter(n_obs == min(n_obs))
```

```{r}
plot_interval <- res_interval %>%
  ggplot(aes(
    n_obs,
    ymin = lower,
    ymax = upper,
    fill = perc,
    group = alpha
  )) +
  geom_ribbon() +
  geom_line(aes(y = median), color = "white") +
  geom_hline(yintercept = true_diff, linetype = "dotted") +
  scale_fill_viridis_c(
    begin = 1,
    end = 0,
    breaks  = 1 - seq(0.05, .2, 0.05),
    labels = . %>% scales::percent(accuracy = 1)
  ) +
  scale_y_continuous(n.breaks = 10) +
  scale_x_continuous(breaks = seq(0, params$nmax, params$nstep * 10)) +
  theme_minimal() +
  labs(x = "N per Group", y = "Standardized Effect Size") +
  theme(legend.title = element_blank()) +
  NULL
```

```{r}
plot_width <- res_interval %>%
  ggplot(aes(n_obs, width, color = perc, group = perc)) +
  geom_line() +
  geom_point(
    data = minn,
    size = 3,
    color = "black",
    shape = 3
  ) +
  scale_color_viridis_c(
    begin = 1,
    end = 0,
    breaks = 1 - seq(0.05, .2, 0.05),
    labels = . %>% scales::percent(accuracy = 1)
  ) +
  theme_minimal() +
  scale_y_log10(breaks = seq(0, 0.8, .1)) +
  scale_x_continuous(breaks = seq(0, params$nmax, params$nstep * 10)) +
  labs(x = "N per Group", y = "Width of quantile\n(Standardized Effect Size)") +
  theme(legend.title = element_blank()) +
  NULL
```

```{r}
plot_interval +
  theme(axis.text.x = element_blank(), axis.title.x = element_blank()) + 
  plot_width +
  plot_layout(nrow = 2, guides = 'collect') +
  plot_annotation(tag_levels = 'A')
ggsave("plot.svg", device = svglite::svglite, width = 7, height = 4)
```

Plot A depicts the range of effect sizes we observed in the simulation, where the colour encodes the density.
The light yellow interval shows where 80% of the estimates land.
The dotted line represents the simulated true effect size; the white line shows the median observed effect sizes.

Plot B represents the width of the interval shown in Plot A on a logarithmic scale.
The cross shows the minimum required sample size so that 80% of the estimates land in a range of +/- .1.

```{r}
nmax <- filter(res_interval, n_obs == max(n_obs))
bias <- (slice(nmax, 1)$median - true_diff)/true_diff
```

We can therefore conclude, that when we want to plan a study where we expect that `r scales::percent(choosen_perc)` of the estimates fall into a range of +/- `r choosen_width/2`, we need a minimum sample size of `r minn$n_obs` per group.
The simulation also shows that we overestimate the effect size by `r scales::percent(bias)` (true: `r true_diff`, median of observed: `round(slice(nmax, 1)$median, 2)`) with a sample size per group of `r slice(nmax, 1)$n_obs`.

# Session Info

```{r}
if(fs::file_exists(hpc_config)){
  list(local = sessioninfo::session_info(),
     login_node = value(future(sessioninfo::session_info())),
     worker = value(future(value(future(sessioninfo::session_info())))))
} else {
  sessioninfo::session_info()
}
```

